{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b36ac30-6d5e-4c27-b9b0-818cb2dfb81f",
   "metadata": {},
   "source": [
    "<h1>Loading modules and checking device</h1>  \n",
    "First, we will load our libraries and check which device we are using, we would prefer using cuda for faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "522c3f84-1132-457b-8a2c-bd34a0681c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import unittest\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as tvtf\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "seed = 318\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "test = unittest.TestCase()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14ac9a4-a68e-4fa5-9499-f4e214fe8071",
   "metadata": {},
   "source": [
    "<h4>Importing Datasets</h4>\n",
    "Now we will download our different datasets, MNIST, CIFAR-10, CIFAR-100 etc.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3a919f-2148-4709-94c6-051219300f98",
   "metadata": {},
   "source": [
    "MNIST Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bfb68b1-991a-4968-9555-1e1f360c1611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 60000 samples\n",
      "Test: 60000 samples\n",
      "MNIST input image size = torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "#MNIST DOWNLOAD\n",
    "data_dir = os.path.expanduser('~/.pytorch-datasets')\n",
    "mnist_train = torchvision.datasets.MNIST(root=data_dir, download=True, train=True, transform=tvtf.ToTensor())\n",
    "mnist_test = torchvision.datasets.MNIST(root=data_dir, download=True, train=False, transform=tvtf.ToTensor())\n",
    "\n",
    "print(f'Train: {len(mnist_train)} samples')\n",
    "print(f'Test: {len(mnist_train)} samples')\n",
    "\n",
    "x0,_ = mnist_train[0]\n",
    "in_size = x0.shape\n",
    "num_classes = 10\n",
    "print('MNIST input image size =', in_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1a00b5-8180-48f9-84cd-8c0a3063daa2",
   "metadata": {},
   "source": [
    "CIFAR-10 Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99cd9c2c-a33c-4424-92a0-bf07da7afb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train: 50000 samples\n",
      "Test: 10000 samples\n",
      "CIFAR-10 input image size = torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "#CIFAR-10 DOWNLOAD\n",
    "data_dir = os.path.expanduser('~/.pytorch-datasets')\n",
    "cifar10_train = torchvision.datasets.CIFAR10(root=data_dir, download=True, train=True, transform=tvtf.ToTensor())\n",
    "cifar10_test = torchvision.datasets.CIFAR10(root=data_dir, download=True, train=False, transform=tvtf.ToTensor())\n",
    "\n",
    "print(f'Train: {len(cifar10_train)} samples')\n",
    "print(f'Test: {len(cifar10_test)} samples')\n",
    "\n",
    "x0,_ = cifar10_train[0]\n",
    "in_size = x0.shape\n",
    "num_classes = 10\n",
    "print('CIFAR-10 input image size =', in_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13353829-df4b-44d8-9b2d-a8579370aaf2",
   "metadata": {},
   "source": [
    "<h1 style=\"color:BLUE\">!!!!CIFAR-100 Download: TO BE ADDED !!!!!</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d122def-35a3-48fc-9e5f-7d5b452952fa",
   "metadata": {},
   "source": [
    "<h4>Importing our experiments</h4>\n",
    "Now, we will load our experiments module for testing the different architectures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c9d10cd-229f-4827-b047-7ef890ff70ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'in_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-07cb9715c177>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Test experiment1 implementation on a few data samples and with a small model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m experiments.run_experiment(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;34m'test_run'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mfilters_per_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers_per_block\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deepAccel/rp-nn/experiments.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(run_name, out_dir, seed, device, bs_train, bs_test, batches, epochs, early_stopping, checkpoints, lr, reg, filters_per_layer, layers_per_block, pool_every, hidden_dims, model_type, dataset, **kw)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mchannels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilters_per_layer\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers_per_block\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mmy_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooling_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mmy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool_every\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmy_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cs236781-hw/lib/python3.8/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mresnet18\u001b[0;34m(pretrained, progress, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mprogress\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplays\u001b[0m \u001b[0ma\u001b[0m \u001b[0mprogress\u001b[0m \u001b[0mbar\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdownload\u001b[0m \u001b[0mto\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \"\"\"\n\u001b[0;32m--> 240\u001b[0;31m     return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress,\n\u001b[0m\u001b[1;32m    241\u001b[0m                    **kwargs)\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cs236781-hw/lib/python3.8/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_resnet\u001b[0;34m(arch, block, layers, pretrained, progress, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_resnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         state_dict = load_state_dict_from_url(model_urls[arch],\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'in_size'"
     ]
    }
   ],
   "source": [
    "import experiments\n",
    "from experiments import load_experiment\n",
    "from utils.plot import plot_fit\n",
    "\n",
    "# Test experiment1 implementation on a few data samples and with a small model\n",
    "experiments.run_experiment(\n",
    "    'test_run', seed=seed, bs_train=50, batches=10, epochs=10, early_stopping=5,\n",
    "    filters_per_layer=[32,64], layers_per_block=1, pool_every=1, hidden_dims=[100],\n",
    "    model_type='fc',\n",
    ")\n",
    "\n",
    "# There should now be a file 'test_run.json' in your `results/` folder.\n",
    "# We can use it to load the results of the experiment.\n",
    "cfg, fit_res = load_experiment('results/test_run_L1_K32-64.json')\n",
    "_, _ = plot_fit(fit_res)\n",
    "\n",
    "# And `cfg` contains the exact parameters to reproduce it\n",
    "print('experiment config: ', cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc72162e-8fef-4844-a34d-9b1d34ba554f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
